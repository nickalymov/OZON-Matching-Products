{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T15:47:51.492720400Z",
     "start_time": "2024-09-06T15:47:50.579697800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import Levenshtein\n",
    "from scipy.stats import entropy\n",
    "import re\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dir = 'C:/Users/Николай/PycharmProjects/OZON E-CUP/competition/'\n",
    "\n",
    "train = pd.read_parquet(f'{dir}train.parquet', engine='pyarrow')\n",
    "\n",
    "test = pd.read_parquet(f'{dir}test.parquet', engine='pyarrow')\n",
    "\n",
    "attributes = pd.read_parquet(f'{dir}attributes.parquet', engine='pyarrow')\n",
    "attributes.set_index('variantid', inplace=True)\n",
    "\n",
    "text = pd.read_parquet(f'{dir}text_and_bert.parquet', engine='pyarrow')\n",
    "text.set_index('variantid', inplace=True)\n",
    "\n",
    "resnet = pd.read_parquet(f'{dir}resnet.parquet', engine='pyarrow')\n",
    "resnet.set_index('variantid', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T15:50:20.719166300Z",
     "start_time": "2024-09-06T15:47:51.494697700Z"
    }
   },
   "id": "9b0e0fc8db968fad",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561848/561848 [00:10<00:00, 55430.94it/s]\n",
      "100%|██████████| 1041973/1041973 [00:00<00:00, 1275364.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество новых пар: 87276\n",
      "   variantid1  variantid2  target\n",
      "0  1042371867  1299689027       1\n",
      "1   105867545   376138947       1\n",
      "2   653782378   690190682       1\n",
      "3  1417344650  1477053699       1\n",
      "4   191644435   489264789       1\n"
     ]
    }
   ],
   "source": [
    "# Фильтруем пары, где target == 1 (только матчи)\n",
    "matched_pairs = train[train['target'] == 1]\n",
    "\n",
    "# Создаем словарь, где ключ — это товар, а значение — это список \"соседей\" (пар с target == 1)\n",
    "neighbor_dict = defaultdict(set)\n",
    "\n",
    "# Заполняем словарь соседями для каждого товара\n",
    "for _, row in tqdm(matched_pairs.iterrows(), total=len(matched_pairs)):\n",
    "    v1, v2 = row['variantid1'], row['variantid2']\n",
    "    neighbor_dict[v1].add(v2)\n",
    "    neighbor_dict[v2].add(v1)\n",
    "\n",
    "# Создаем множество существующих пар для быстрой проверки\n",
    "existing_pairs = set(tuple(sorted([row['variantid1'], row['variantid2']])) for _, row in train.iterrows())\n",
    "\n",
    "# Собираем новые пары (v1, v3), которых нет в train\n",
    "new_pairs = set()\n",
    "for v1 in tqdm(neighbor_dict, total=len(neighbor_dict)):\n",
    "    # Для каждого соседа v2 товара v1\n",
    "    for v2 in neighbor_dict[v1]:\n",
    "        # Проверяем соседей v3 для v2 (они будут потенциальными v3 для v1)\n",
    "        for v3 in neighbor_dict[v2]:\n",
    "            # Исключаем повторение и пары вида (v1, v1)\n",
    "            if v3 != v1:\n",
    "                # Сортируем для уникальности (чтобы (v1, v3) и (v3, v1) считались одной и той же парой)\n",
    "                new_pair = tuple(sorted([v1, v3]))\n",
    "                # Добавляем пару, если ее еще нет в существующих\n",
    "                if new_pair not in existing_pairs:\n",
    "                    new_pairs.add(new_pair)\n",
    "print(f\"Количество новых пар: {len(new_pairs)}\")\n",
    "# Создаем DataFrame из новых пар\n",
    "new_pairs = pd.DataFrame(new_pairs, columns=['variantid1', 'variantid2'])\n",
    "\n",
    "# Добавляем колонку target и присваиваем ей значение 1 (так как это новые матчи)\n",
    "new_pairs['target'] = 1\n",
    "\n",
    "# Выводим первые несколько строк DataFrame\n",
    "print(new_pairs.head())\n",
    "# Приводим колонки variantid1 и variantid2 к типу int\n",
    "new_pairs['variantid1'] = new_pairs['variantid1'].astype(int)\n",
    "new_pairs['variantid2'] = new_pairs['variantid2'].astype(int)\n",
    "train = pd.concat([train, new_pairs], ignore_index=True)\n",
    "train.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T15:50:49.472167600Z",
     "start_time": "2024-09-06T15:50:20.711167100Z"
    }
   },
   "id": "c6d074ce4585320b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 1255792\n",
      "len wrongs: 786\n",
      "len duplicates: 4334\n",
      "len train: 1250672\n"
     ]
    }
   ],
   "source": [
    "print('len train:', len(train))\n",
    "merged_df = train.merge(train, left_on=['variantid1', 'variantid2'], right_on=['variantid2', 'variantid1'], suffixes=('_left', '_right'))\n",
    "\n",
    "wrongs = merged_df[merged_df['target_left'] != merged_df['target_right']]\n",
    "duplicates = merged_df[merged_df['target_left'] == merged_df['target_right']]\n",
    "duplicates = duplicates[duplicates['variantid1_left'] > duplicates['variantid2_left']].index\n",
    "\n",
    "print('len wrongs:', len(wrongs))\n",
    "train.drop(wrongs.index, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('len duplicates:', len(duplicates))\n",
    "train.drop(duplicates, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print('len train:', len(train))\n",
    "\n",
    "del wrongs, duplicates, merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T15:50:50.362167700Z",
     "start_time": "2024-09-06T15:50:49.477167200Z"
    }
   },
   "id": "4472ca1f411b1a49",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cats = attributes['categories'].tolist()\n",
    "\n",
    "unique_strings = set()\n",
    "for cat in cats:\n",
    "    unique_strings.add(json.loads(cat)['2'])\n",
    "unique_cats2 = {string: idx for idx, string in enumerate(set(unique_strings))}\n",
    "\n",
    "unique_strings = set()\n",
    "for cat in cats:\n",
    "    unique_strings.add(json.loads(cat)['3'])\n",
    "unique_cats3 = {string: idx for idx, string in enumerate(set(unique_strings))}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T15:50:57.654167600Z",
     "start_time": "2024-09-06T15:50:50.364165600Z"
    }
   },
   "id": "dcd017c4e9861c28",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250672/1250672 [01:25<00:00, 14642.64it/s]\n"
     ]
    }
   ],
   "source": [
    "common_set = set()\n",
    "t0 = {}\n",
    "t1 = {}\n",
    "for index, row in tqdm(train.iterrows(), total=len(train)):\n",
    "        \n",
    "    v1 = row['variantid1']\n",
    "    v2 = row['variantid2']\n",
    "\n",
    "    attr1 = json.loads(attributes.loc[v1, 'characteristic_attributes_mapping'])\n",
    "    attr2 = json.loads(attributes.loc[v2, 'characteristic_attributes_mapping'])\n",
    "    \n",
    "    common_attrs = set(attr1.keys()).intersection(set(attr2.keys()))\n",
    "    \n",
    "    target = row['target']\n",
    "    \n",
    "    if target == 1:\n",
    "        for key in common_attrs:\n",
    "            if set(attr1[key]) == set(attr2[key]):\n",
    "                if key in t1:\n",
    "                    t1[key][0] += 1\n",
    "                else:\n",
    "                    t1[key] = [1, 0]\n",
    "            else:\n",
    "                if key in t1:\n",
    "                    t1[key][1] += 1\n",
    "                else:\n",
    "                    t1[key] = [0, 1]\n",
    "\n",
    "    if target == 0:\n",
    "        for key in common_attrs:\n",
    "            if set(attr1[key]) == set(attr2[key]):\n",
    "                if key in t0:\n",
    "                    t0[key][0] += 1\n",
    "                else:\n",
    "                    t0[key] = [1, 0]\n",
    "            else:\n",
    "                if key in t0:\n",
    "                    t0[key][1] += 1\n",
    "                else:\n",
    "                    t0[key] = [0, 1]\n",
    "                    \n",
    "vital_keys = []\n",
    "minor_keys = []\n",
    "for key in t1:\n",
    "    if key in t0:\n",
    "        if t1[key][0] > t1[key][1] and t0[key][0] < t0[key][1] or t1[key][0] < t1[key][1] and t0[key][0] > t0[key][1]:\n",
    "            vital_keys.append(key)\n",
    "        else:\n",
    "            minor_keys.append(key)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T15:52:23.098158600Z",
     "start_time": "2024-09-06T15:50:57.670165900Z"
    }
   },
   "id": "5071442895406a8e",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# categories - attributes / cat - attrs\n",
    "# name - description / n - d\n",
    "# main_pics - extra - pics / m - e\n",
    "CONFIG = {\n",
    "    'text_process': True, # Составление name, description только для - слов (удаление пунктуации) / русских слов / английских слов / слов содержащих русские символы / слов содержащих английские символы / кобминации цифр \n",
    "    \n",
    "    # attributes\n",
    "    'cat_fit': True, # Количество одинаковых категорий / 4 \n",
    "    'cat2': True, # Категориальный признак 2 категории\n",
    "    'cat3': True, # Категориальный признак 3 категории\n",
    "    'jac_attrs': True, # Сходство Жаккара для аттрибутов (только ключей) \n",
    "    'jac_vals': True, # Среднее сходств Жаккара для значений (для общих ключей)\n",
    "    'jac_num_vals': True, # Сходство Жаккара для числовых общих значений\n",
    "    'jac_sev_vals': True, # Сходство Жаккара для общих значений в ключах (значений в ключе > 1)\n",
    "    'jac_vital_vals':True, # Сходство значений значимых ключей (по статистике выше)\n",
    "    'jac_minor_vals':True, # Сходство незначений значимых ключей (по статистике выше)\n",
    "    'diff_attrs': True, # Разность количеств аттрибутов (ключей) / max(len(attrs1), len(attrs2))\n",
    "    \n",
    "    # text\n",
    "    'n_len_diff': True, # Разность количеств символов имен / max(len(name1), len(name2))\n",
    "    'd_len_diff': True, # Разность количеств символов описаний / max(len(desc1), len(desc2))\n",
    "    'n_lev': True, # Расстояние Левенштейна между именами / max(len(name1), len(name2))\n",
    "    'd_lev': True, # Расстояние Левенштейна между описаниями / max(len(desc1), len(desc2))\n",
    "    'n_jac_symbs': True, # Жаккарово сравнение символов имен\n",
    "    'd_jac_symbs': True, # Жаккарово сравнение символов описаний\n",
    "    \n",
    "    'n_jac': True, # Жаккарово сравнение имен по 6 вариантам токенизации\n",
    "    'd_jac': True, # Жаккарово сравнение описаний по 6 вариантам токенизации\n",
    "    'n_lev_opers': True, # Расстояние Левенштейна между именами / max(len(name1), len(name2))\n",
    "    'd_lev_opers': True, # Расстояние Левенштейна между описаниями / max(len(desc1), len(desc2))\n",
    "    \n",
    "    # resnet\n",
    "    'm_cos': True, # Косинусное сходство между основными эмбеддингами\n",
    "    'm_evklid': True, # Евклидово расстояние между основными эмбеддингами\n",
    "    'e_jac': True, # Жаккарово сравнение дополнительных эмбеддингов\n",
    "    'e_diff': True, # Разница в количестве дополнительных эмбеддингов\n",
    "    'm_ent_diff': True, # Энтропия (не знаю что за функция) основных эмбеддингов\n",
    "    'e_avg_cos': True, # Косинусное сходство между средним эмбеддингом дополнительных эмбеддингов\n",
    "\n",
    "    'n_years': True,\n",
    "    'd_years': True,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T15:52:23.125157900Z",
     "start_time": "2024-09-06T15:52:23.101158300Z"
    }
   },
   "id": "3325239ac830f252",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing name: 100%|██████████| 2252569/2252569 [03:01<00:00, 12392.84it/s]\n",
      "Processing description: 100%|██████████| 2252569/2252569 [14:03<00:00, 2669.55it/s] \n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('text_process', False):\n",
    "    def text_process(sentence):\n",
    "        if sentence is None:\n",
    "            return None, None, None, None\n",
    "        # Общая обработка\n",
    "        sentence = sentence.replace('\\n', ' ').lower()\n",
    "        \n",
    "        # Токены без пунктуации\n",
    "        words = re.sub(r'[^\\w\\s]', ' ', sentence) # Unicode токены\n",
    "        words = words.replace('_', ' ') # Удаление _ символов\n",
    "        words = re.sub(r'\\s+', ' ', words) # Удаление лишних пробелов\n",
    "        words = words.strip() # Удаление пробелов в начале и конце\n",
    "        \n",
    "        # Токенов, содержащих только русские буквы\n",
    "        ru_words = re.sub(r'[^а-яА-Я]', ' ', sentence) # Получение токенов с ру символами\n",
    "        ru_words = re.sub(r'\\s+', ' ', ru_words) # Удаление лишних пробелов\n",
    "        ru_words = ru_words.strip() # Удаление пробелов в начале и конце\n",
    "        \n",
    "        # Токенов, содержащих только английские буквы\n",
    "        en_words = re.sub(r'[^a-zA-Z]', ' ', sentence) # Получение токенов с ру символами\n",
    "        en_words = re.sub(r'\\s+', ' ', en_words) # Удаление лишних пробелов\n",
    "        en_words = en_words.strip() # Удаление пробелов в начале и конце\n",
    "        \n",
    "        # Токены, где содержатся ру символы (токены не состоят целиком из ру символов - testовое)\n",
    "        ru_comb_words = re.sub(r'[^\\w\\s]', ' ', sentence) # Unicode токены\n",
    "        ru_comb_words = ru_comb_words.replace('_', ' ') # Удаление _ символов\n",
    "        ru_comb_words = ' '.join(re.findall(r'\\b(?=\\w*[а-яА-Я])(?=\\w*[^\\Wа-яА-Я])\\w+\\b', ru_comb_words))\n",
    "        ru_comb_words = re.sub(r'\\s+', ' ', ru_comb_words) # Удаление лишних пробелов\n",
    "        ru_comb_words = ru_comb_words.strip() # Удаление пробелов в начале и конце\n",
    "        \n",
    "        # Токены, где содержатся en символы (токены не состоят целиком из en символов - testовое)\n",
    "        en_comb_words = re.sub(r'[^\\w\\s]', ' ', sentence) # Unicode токены\n",
    "        en_comb_words = en_comb_words.replace('_', ' ') # Удаление _ символов\n",
    "        en_comb_words = ' '.join(re.findall(r'\\b(?=\\w*[a-zA-Z])(?=\\w*[^\\Wa-zA-Z])\\w+\\b', en_comb_words))\n",
    "        en_comb_words = re.sub(r'\\s+', ' ', en_comb_words) # Удаление лишних пробелов\n",
    "        en_comb_words = en_comb_words.strip() # Удаление пробелов в начале и конце\n",
    "         \n",
    "        # Токены в виде цифр\n",
    "        numbers = re.sub(r'[^\\d]', ' ', sentence) # Получение токенов с цифрами\n",
    "        numbers = re.sub(r'\\s+', ' ', numbers) # Удаление лишних пробелов\n",
    "        numbers = numbers.strip() # Удаление пробелов в начале и конце\n",
    "\n",
    "        return words, ru_words, en_words, ru_comb_words, en_comb_words, numbers\n",
    "    \n",
    "    # Применение функции и распаковка значений в 4 отдельные колонки для name\n",
    "    tqdm.pandas(desc='Processing name')\n",
    "    text[['n_words', 'n_ru_words', 'n_en_words', 'n_ru_comb_words', 'n_en_comb_words', 'n_numbers']] = text['name'].progress_apply(\n",
    "        lambda x: pd.Series(text_process(x)))\n",
    "    \n",
    "    # Применение функции и распаковка значений в 4 отдельные колонки для description\n",
    "    tqdm.pandas(desc='Processing description')\n",
    "    text[['d_words', 'd_ru_words', 'd_en_words', 'd_ru_comb_words', 'd_en_comb_words', 'd_numbers']] = text['description'].progress_apply(\n",
    "        lambda x: pd.Series(text_process(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:09:29.513406400Z",
     "start_time": "2024-09-06T15:52:23.117158Z"
    }
   },
   "id": "839fc378fe3ace2e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:20<00:00, 62067.78it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:00<00:00, 61795.99it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('cat_fit', False):\n",
    "    def cat_fit(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_cat_fit(variantid1, variantid2):\n",
    "            \n",
    "            cat1 = json.loads(attributes_df.at[variantid1, 'categories'])\n",
    "            cat2 = json.loads(attributes_df.at[variantid2, 'categories'])\n",
    "                \n",
    "            common_keys = set(cat1.keys()) & set(cat2.keys())\n",
    "            \n",
    "            return (sum(1 for key in common_keys if cat1[key] == cat2[key])) / len(common_keys)\n",
    "            \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['cat_fit'] = train_df.progress_apply(lambda row: compute_cat_fit(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['cat_fit'] = test_df.progress_apply(lambda row: compute_cat_fit(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = cat_fit(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:09:50.495405800Z",
     "start_time": "2024-09-06T16:09:29.526424400Z"
    }
   },
   "id": "84eb6c7c79598edb",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:18<00:00, 68873.15it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:00<00:00, 65723.84it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('cat2', False):\n",
    "    def cat2(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_cat2(variantid1, variantid2, u_cats=unique_cats2):\n",
    "            \n",
    "            cat1 = json.loads(attributes_df.at[variantid1, 'categories'])\n",
    "            cat2 = json.loads(attributes_df.at[variantid2, 'categories'])\n",
    "            \n",
    "            if cat1['2'] == cat2['2']:\n",
    "                if cat1['2'] in u_cats:\n",
    "                    return u_cats[cat1['2']]\n",
    "                else:\n",
    "                    return -2\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['cat2'] = train_df.progress_apply(lambda row: compute_cat2(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['cat2'] = test_df.progress_apply(lambda row: compute_cat2(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = cat2(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:10:09.435406500Z",
     "start_time": "2024-09-06T16:09:50.498405900Z"
    }
   },
   "id": "f90621689137356b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:18<00:00, 68402.19it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:00<00:00, 65289.37it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('cat3', False):\n",
    "    def cat3(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_cat3(variantid1, variantid2, u_cats=unique_cats3):\n",
    "            \n",
    "            cat1 = json.loads(attributes_df.at[variantid1, 'categories'])\n",
    "            cat2 = json.loads(attributes_df.at[variantid2, 'categories'])\n",
    "            \n",
    "            if cat1['3'] == cat2['3']:\n",
    "                if cat1['3'] in u_cats:\n",
    "                    return u_cats[cat1['3']]\n",
    "                else:\n",
    "                    return -2\n",
    "            else:\n",
    "                return -1\n",
    "            \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['cat3'] = train_df.progress_apply(lambda row: compute_cat3(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['cat3'] = test_df.progress_apply(lambda row: compute_cat3(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = cat3(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:10:28.512422700Z",
     "start_time": "2024-09-06T16:10:09.439411100Z"
    }
   },
   "id": "85c2226180d09002",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [01:18<00:00, 15898.27it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 34220.67it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('jac_attrs', False):\n",
    "    def jac_attrs(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_jac_attrs(variantid1, variantid2):\n",
    "            \n",
    "            attrs1 = json.loads(attributes_df.at[variantid1, 'characteristic_attributes_mapping'])\n",
    "            attrs2 = json.loads(attributes_df.at[variantid2, 'characteristic_attributes_mapping'])\n",
    "            \n",
    "            keys1 = set(attrs1.keys())\n",
    "            keys2 = set(attrs2.keys())\n",
    "            \n",
    "            if len(keys1) == 0 or len(keys2) == 0:\n",
    "                if len(keys1) == 0 and len(keys2) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "                \n",
    "            intersection = len(keys1.intersection(keys2))\n",
    "            union = len(keys1.union(keys2))\n",
    "            \n",
    "            return intersection / union if union != 0 else 0\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['jac_attrs'] = train_df.progress_apply(lambda row: compute_jac_attrs(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['jac_attrs'] = test_df.progress_apply(lambda row: compute_jac_attrs(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = jac_attrs(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:11:48.658543Z",
     "start_time": "2024-09-06T16:10:28.517405900Z"
    }
   },
   "id": "fe50b7af4ee05452",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:41<00:00, 30025.25it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 30993.15it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('jac_vals', False):\n",
    "    def jac_vals(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_jac_vals(variantid1, variantid2):\n",
    "            attrs1 = json.loads(attributes_df.at[variantid1, 'characteristic_attributes_mapping'])\n",
    "            attrs2 = json.loads(attributes_df.at[variantid2, 'characteristic_attributes_mapping'])\n",
    "            \n",
    "            \n",
    "            common_keys = set(attrs1.keys()).intersection(set(attrs2.keys()))\n",
    "\n",
    "            if not common_keys:\n",
    "                return -2  \n",
    "\n",
    "            jaccard_scores = []\n",
    "\n",
    "            for key in common_keys:\n",
    "                set_values1 = set(attrs1[key])\n",
    "                set_values2 = set(attrs2[key])\n",
    "    \n",
    "                intersection = len(set_values1.intersection(set_values2))\n",
    "                union = len(set_values1.union(set_values2))\n",
    "                \n",
    "                jaccard_score = intersection / union if union != 0 else 0\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "            \n",
    "            return sum(jaccard_scores) / len(jaccard_scores)\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['jac_vals'] = train_df.progress_apply(lambda row: compute_jac_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['jac_vals'] = test_df.progress_apply(lambda row: compute_jac_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = jac_vals(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:12:31.946543100Z",
     "start_time": "2024-09-06T16:11:48.666543500Z"
    }
   },
   "id": "ed6e5188b841c397",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:39<00:00, 31940.62it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 30404.40it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('jac_num_vals', False):\n",
    "    def jac_num_vals(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_jac_num_vals(variantid1, variantid2):\n",
    "            \n",
    "            attrs1 = json.loads(attributes_df.at[variantid1, 'characteristic_attributes_mapping'])\n",
    "            attrs2 = json.loads(attributes_df.at[variantid2, 'characteristic_attributes_mapping'])\n",
    "            \n",
    "            \n",
    "            common_keys = set(attrs1.keys()).intersection(set(attrs2.keys()))\n",
    "            \n",
    "            if not common_keys:\n",
    "                return -2  \n",
    "            \n",
    "            num_common_keys = set()\n",
    "            \n",
    "            for key in common_keys:\n",
    "                if len(attrs1[key]) == len(attrs2[key]):\n",
    "                    digit = True\n",
    "                    for val1, val2 in zip(attrs1[key], attrs2[key]):\n",
    "                        if val1.isdigit() and val2.isdigit():\n",
    "                            continue\n",
    "                        else:\n",
    "                            digit = False\n",
    "                    if digit:\n",
    "                        num_common_keys.add(key)\n",
    "            \n",
    "            if len(num_common_keys) == 0:\n",
    "                return -3\n",
    "            \n",
    "            jaccard_scores = []\n",
    "\n",
    "            for key in num_common_keys:\n",
    "                set_values1 = set(attrs1[key])\n",
    "                set_values2 = set(attrs2[key])\n",
    "    \n",
    "                intersection = len(set_values1.intersection(set_values2))\n",
    "                union = len(set_values1.union(set_values2))\n",
    "                \n",
    "                jaccard_score = intersection / union if union != 0 else 0\n",
    "                \n",
    "                jaccard_scores.append(jaccard_score)\n",
    "            \n",
    "            return sum(jaccard_scores) / len(jaccard_scores)\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['jac_num_vals'] = train_df.progress_apply(\n",
    "            lambda row: compute_jac_num_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['jac_num_vals'] = test_df.progress_apply(\n",
    "            lambda row: compute_jac_num_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = jac_num_vals(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:13:12.761680Z",
     "start_time": "2024-09-06T16:12:31.954543100Z"
    }
   },
   "id": "162ed7add62575d4",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:34<00:00, 36377.87it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 37196.39it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('jac_sev_vals', False):\n",
    "    def jac_sev_vals(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_jac_sev_vals(variantid1, variantid2):\n",
    "            \n",
    "            attrs1 = json.loads(attributes_df.at[variantid1, 'characteristic_attributes_mapping'])\n",
    "            attrs2 = json.loads(attributes_df.at[variantid2, 'characteristic_attributes_mapping'])\n",
    "            \n",
    "            \n",
    "            common_keys = set(attrs1.keys()).intersection(set(attrs2.keys()))\n",
    "            \n",
    "            if not common_keys:\n",
    "                return -2  \n",
    "            \n",
    "            sev_common_keys = set()\n",
    "            \n",
    "            for key in common_keys:\n",
    "                if len(attrs1[key]) > 1 or len(attrs2[key]) > 1:\n",
    "                        sev_common_keys.add(key)\n",
    "            \n",
    "            if len(sev_common_keys) == 0:\n",
    "                return -3\n",
    "            \n",
    "            jaccard_scores = []\n",
    "\n",
    "            for key in sev_common_keys:\n",
    "                set_values1 = set(attrs1[key])\n",
    "                set_values2 = set(attrs2[key])\n",
    "    \n",
    "                intersection = len(set_values1.intersection(set_values2))\n",
    "                union = len(set_values1.union(set_values2))\n",
    "                \n",
    "                jaccard_score = intersection / union if union != 0 else 0\n",
    "                \n",
    "                jaccard_scores.append(jaccard_score)\n",
    "            \n",
    "            return sum(jaccard_scores) / len(jaccard_scores)\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['jac_sev_vals'] = train_df.progress_apply(\n",
    "            lambda row: compute_jac_sev_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['jac_sev_vals'] = test_df.progress_apply(\n",
    "            lambda row: compute_jac_sev_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = jac_sev_vals(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:13:48.502679900Z",
     "start_time": "2024-09-06T16:13:12.766680600Z"
    }
   },
   "id": "8a6a3e9057b90f77",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [01:33<00:00, 13321.86it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:03<00:00, 14750.54it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('jac_vital_vals', False):\n",
    "    def jac_vital_vals(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_jac_vital_vals(variantid1, variantid2, v_keys=vital_keys):\n",
    "            \n",
    "            attrs1 = json.loads(attributes_df.at[variantid1, 'characteristic_attributes_mapping'])\n",
    "            attrs2 = json.loads(attributes_df.at[variantid2, 'characteristic_attributes_mapping'])\n",
    "            \n",
    "            \n",
    "            common_keys = set(attrs1.keys()).intersection(set(attrs2.keys()))\n",
    "\n",
    "            if not common_keys:\n",
    "                return -2  \n",
    "            \n",
    "            common_vital_keys = set()\n",
    "            \n",
    "            for key in common_keys:\n",
    "                if key in v_keys:\n",
    "                    common_vital_keys.add(key)\n",
    "            \n",
    "            if len(common_vital_keys) == 0:\n",
    "                return -3\n",
    "                    \n",
    "            jaccard_scores = []\n",
    "\n",
    "            for key in common_vital_keys:\n",
    "                set_values1 = set(attrs1[key])\n",
    "                set_values2 = set(attrs2[key])\n",
    "    \n",
    "                intersection = len(set_values1.intersection(set_values2))\n",
    "                union = len(set_values1.union(set_values2))\n",
    "                \n",
    "                jaccard_score = intersection / union if union != 0 else 0\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "            \n",
    "            return sum(jaccard_scores) / len(jaccard_scores)\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['jac_vital_vals'] = train_df.progress_apply(\n",
    "            lambda row: compute_jac_vital_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['jac_vital_vals'] = test_df.progress_apply(\n",
    "            lambda row: compute_jac_vital_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = jac_vital_vals(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:15:25.778814800Z",
     "start_time": "2024-09-06T16:13:48.508679700Z"
    }
   },
   "id": "63211e22afcedb70",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [01:57<00:00, 10679.90it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:04<00:00, 11876.24it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('jac_minor_vals', False):\n",
    "    def jac_minor_vals(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_jac_minor_vals(variantid1, variantid2, m_keys=minor_keys):\n",
    "            attrs1 = json.loads(attributes_df.at[variantid1, 'characteristic_attributes_mapping'])\n",
    "            attrs2 = json.loads(attributes_df.at[variantid2, 'characteristic_attributes_mapping'])\n",
    "            \n",
    "            \n",
    "            common_keys = set(attrs1.keys()).intersection(set(attrs2.keys()))\n",
    "\n",
    "            if not common_keys:\n",
    "                return -2  \n",
    "            \n",
    "            common_minor_keys = set()\n",
    "            \n",
    "            for key in common_keys:\n",
    "                if key in m_keys:\n",
    "                    common_minor_keys.add(key)\n",
    "            \n",
    "            if len(common_minor_keys) == 0:\n",
    "                return -3\n",
    "                    \n",
    "            jaccard_scores = []\n",
    "\n",
    "            for key in common_minor_keys:\n",
    "                set_values1 = set(attrs1[key])\n",
    "                set_values2 = set(attrs2[key])\n",
    "    \n",
    "                intersection = len(set_values1.intersection(set_values2))\n",
    "                union = len(set_values1.union(set_values2))\n",
    "                \n",
    "                jaccard_score = intersection / union if union != 0 else 0\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "            \n",
    "            return sum(jaccard_scores) / len(jaccard_scores)\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['jac_minor_vals'] = train_df.progress_apply(lambda row: compute_jac_minor_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['jac_minor_vals'] = test_df.progress_apply(lambda row: compute_jac_minor_vals(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = jac_minor_vals(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:17:27.080974900Z",
     "start_time": "2024-09-06T16:15:25.783814700Z"
    }
   },
   "id": "1ac32d67f7fd42c9",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:28<00:00, 44495.14it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 45611.05it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('diff_attrs', False):\n",
    "    def diff_attrs(train_df, test_df, attributes_df):\n",
    "        \n",
    "        def compute_diff_attrs(variantid1, variantid2):\n",
    "            attrs1 = json.loads(attributes_df.at[variantid1, 'characteristic_attributes_mapping'])\n",
    "            attrs2 = json.loads(attributes_df.at[variantid2, 'characteristic_attributes_mapping'])\n",
    "            \n",
    "            return (abs(len(attrs1) - len(attrs2))) / max(len(attrs1), len(attrs2))\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['diff_attrs'] = train_df.progress_apply(lambda row: compute_diff_attrs(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['diff_attrs'] = test_df.progress_apply(lambda row: compute_diff_attrs(row['variantid1'], row['variantid2']), axis=1)\n",
    "\n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = diff_attrs(train, test, attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:17:56.315928100Z",
     "start_time": "2024-09-06T16:17:27.103964300Z"
    }
   },
   "id": "d3257e9795a55f65",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:17<00:00, 73447.58it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:00<00:00, 80814.32it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('n_len_diff', False):\n",
    "    def n_len_diff(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_n_len_diff(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'name']\n",
    "            name2 = text_df.at[variantid2, 'name']\n",
    "                \n",
    "            if len(name1.replace(' ', '')) == 0  or len(name2.replace(' ', '')) == 0:\n",
    "                if len(name1.replace(' ', '')) == 0  and len(name2.replace(' ', '')) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            return abs(len(name1) - len(name2)) / max(len(name1), len(name2))\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['n_len_diff'] = train_df.progress_apply(lambda row: compute_n_len_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['n_len_diff'] = test_df.progress_apply(lambda row: compute_n_len_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = n_len_diff(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:18:13.986019Z",
     "start_time": "2024-09-06T16:17:56.321927600Z"
    }
   },
   "id": "a9b5487bce01c6f",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:51<00:00, 24401.03it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:00<00:00, 55885.16it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('d_len_diff', False):\n",
    "    def d_len_diff(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_d_len_diff(variantid1, variantid2):\n",
    "            \n",
    "            desc1 = text_df.at[variantid1, 'description']\n",
    "            desc2 = text_df.at[variantid2, 'description']\n",
    "            \n",
    "            if desc1 is None or desc2 is None:\n",
    "                if desc1 is None and desc2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "                \n",
    "            if len(desc1.replace(' ', '')) == 0  or len(desc2.replace(' ', '')) == 0:\n",
    "                if len(desc1.replace(' ', '')) == 0  and len(desc2.replace(' ', '')) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "                \n",
    "            return abs(len(desc1) - len(desc2)) / max(len(desc1), len(desc2))\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['d_len_diff'] = train_df.progress_apply(lambda row: compute_d_len_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['d_len_diff'] = test_df.progress_apply(lambda row: compute_d_len_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = d_len_diff(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:19:06.158802300Z",
     "start_time": "2024-09-06T16:18:13.992018600Z"
    }
   },
   "id": "f3c06efbbfbc4160",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:16<00:00, 76907.16it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:00<00:00, 74853.62it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('n_lev', False):\n",
    "    def n_lev(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_n_lev(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'name']\n",
    "            name2 = text_df.at[variantid2, 'name']\n",
    "\n",
    "            if len(name1.replace(' ', '')) == 0  or len(name2.replace(' ', '')) == 0:\n",
    "                if len(name1.replace(' ', '')) == 0  and len(name2.replace(' ', '')) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "                \n",
    "            return Levenshtein.distance(name1, name2) / max(len(name1), len(name2))\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['n_lev'] = train_df.progress_apply(lambda row: compute_n_lev(row['variantid1'], row['variantid2']), axis=1)\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['n_lev'] = test_df.progress_apply(lambda row: compute_n_lev(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = n_lev(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:19:23.116802200Z",
     "start_time": "2024-09-06T16:19:06.165802Z"
    }
   },
   "id": "abaa8f990dd73850",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [01:06<00:00, 18757.73it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:04<00:00, 10095.42it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('d_lev', False):\n",
    "    def d_lev(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_d_lev(variantid1, variantid2):\n",
    "            \n",
    "            desc1 = text_df.at[variantid1, 'description']\n",
    "            desc2 = text_df.at[variantid2, 'description']\n",
    "            \n",
    "            if desc1 is None or desc2 is None:\n",
    "                if desc1 is None and desc2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            if len(desc1.replace(' ', '')) == 0  or len(desc2.replace(' ', '')) == 0:\n",
    "                if len(desc1.replace(' ', '')) == 0  and len(desc2.replace(' ', '')) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "                \n",
    "            return Levenshtein.distance(desc1, desc2) / max(len(desc1), len(desc2))\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['d_lev'] = train_df.progress_apply(lambda row: compute_d_lev(row['variantid1'], row['variantid2']), axis=1)\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['d_lev'] = test_df.progress_apply(lambda row: compute_d_lev(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = d_lev(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:20:34.738890500Z",
     "start_time": "2024-09-06T16:19:23.122802100Z"
    }
   },
   "id": "e504480f20305dfd",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:38<00:00, 32578.91it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 26252.62it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('n_jac_symbs', False):\n",
    "    def n_jac_symbs(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_n_jac_symbs(variantid1, variantid2):\n",
    "            \n",
    "            symbols1 = set(text_df.at[variantid1, 'name'])\n",
    "            symbols2 = set(text_df.at[variantid2, 'name'])\n",
    "            \n",
    "            if len(symbols1) == 0 or len(symbols2) == 0:\n",
    "                if len(symbols1) == 0 and len(symbols2) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            intersection = len(symbols1.intersection(symbols2))\n",
    "            union = len(symbols1.union(symbols2))\n",
    "            \n",
    "            return intersection / union if union != 0 else 0\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['n_jac_symbs'] = train_df.progress_apply(lambda row: compute_n_jac_symbs(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['n_jac_symbs'] = test_df.progress_apply(lambda row: compute_n_jac_symbs(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = n_jac_symbs(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:21:15.050917400Z",
     "start_time": "2024-09-06T16:20:34.734909600Z"
    }
   },
   "id": "8164d4d236a2daf0",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [02:04<00:00, 10053.55it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:04<00:00, 10307.43it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('d_jac_symbs', False):\n",
    "    def d_jac_symbs(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_d_jac_symbs(variantid1, variantid2):\n",
    "            \n",
    "            desc1 = text_df.at[variantid1, 'description']\n",
    "            desc2 = text_df.at[variantid2, 'description']\n",
    "            \n",
    "            if desc1 is None or desc2 is None:\n",
    "                if desc1 is None and desc2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            if len(desc1) == 0 or len(desc2) == 0:\n",
    "                if len(desc1) == 0 and len(desc2) == 0: \n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            \n",
    "            symbols1 = set(desc1)\n",
    "            symbols2 = set(desc2)\n",
    "            \n",
    "            intersection = len(symbols1.intersection(symbols2))\n",
    "            union = len(symbols1.union(symbols2))\n",
    "            \n",
    "            return intersection / union if union != 0 else 0\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['d_jac_symbs'] = train_df.progress_apply(lambda row: compute_d_jac_symbs(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['d_jac_symbs'] = test_df.progress_apply(lambda row: compute_d_jac_symbs(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = d_jac_symbs(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:23:24.306923900Z",
     "start_time": "2024-09-06T16:21:15.057915600Z"
    }
   },
   "id": "9b5d9a1ae30e7cb4",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 1250672/1250672 [04:55<00:00, 4238.61it/s] \n",
      "Processing test: 100%|██████████| 49620/49620 [00:05<00:00, 9394.32it/s] \n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('n_jac', False):\n",
    "    def n_jac(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_jac_value(tokens1, tokens2):\n",
    "            \n",
    "            if len(tokens1) == 0  or len(tokens2) == 0 :\n",
    "                if len(tokens1) == 0  and len(tokens2) == 0 :\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            intersection = len(tokens1.intersection(tokens2))\n",
    "            union = len(tokens1.union(tokens2))\n",
    "            \n",
    "            return intersection / union if union > 0 else 0\n",
    "        \n",
    "        def compute_n_jac(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'name']\n",
    "            name2 = text_df.at[variantid2, 'name']\n",
    "            \n",
    "            if len(name1.replace(' ', '')) == 0  or len(name2.replace(' ', '')) == 0 :\n",
    "                if len(name1.replace(' ', '')) == 0  and len(name2.replace(' ', '')) == 0 :\n",
    "                    return -2, -2, -2, -2, -2, -2\n",
    "                else:\n",
    "                    return -1, -1, -1 , -1, -1, -1\n",
    "                \n",
    "            words1 = set(text_df.at[variantid1, 'n_words'].split())\n",
    "            words2 = set(text_df.at[variantid2, 'n_words'].split())\n",
    "            n_jac_words = compute_jac_value(words1, words2)\n",
    "            \n",
    "            ru_words1 = set(text_df.at[variantid1, 'n_ru_words'].split())\n",
    "            ru_words2 = set(text_df.at[variantid2, 'n_ru_words'].split())\n",
    "            n_jac_ru_words = compute_jac_value(ru_words1, ru_words2)\n",
    "            \n",
    "            en_words1 = set(text_df.at[variantid1, 'n_en_words'].split())\n",
    "            en_words2 = set(text_df.at[variantid2, 'n_en_words'].split())\n",
    "            n_jac_en_words = compute_jac_value(en_words1, en_words2)\n",
    "            \n",
    "            ru_comb_words1 = set(text_df.at[variantid1, 'n_ru_comb_words'].split())\n",
    "            ru_comb_words2 = set(text_df.at[variantid2, 'n_ru_comb_words'].split())\n",
    "            n_jac_ru_comb_words = compute_jac_value(ru_comb_words1, ru_comb_words2)\n",
    "            \n",
    "            en_comb_words1 = set(text_df.at[variantid1, 'n_en_comb_words'].split())\n",
    "            en_comb_words2 = set(text_df.at[variantid2, 'n_en_comb_words'].split())\n",
    "            n_jac_en_comb_words = compute_jac_value(en_comb_words1, en_comb_words2)\n",
    "            \n",
    "            numbers1 = set(text_df.at[variantid1, 'n_numbers'].split())\n",
    "            numbers2 = set(text_df.at[variantid2, 'n_numbers'].split())\n",
    "            n_jac_numbers = compute_jac_value(numbers1, numbers2)\n",
    "        \n",
    "            return n_jac_words, n_jac_ru_words, n_jac_en_words, n_jac_ru_comb_words, n_jac_en_comb_words, n_jac_numbers\n",
    "    \n",
    "        tqdm.pandas(desc='Processing train')\n",
    "        train_df[['n_jac_words', 'n_jac_ru_words', 'n_jac_en_words', 'n_jac_ru_comb_words', 'n_jac_en_comb_words', 'n_jac_numbers']] = train_df.progress_apply(lambda row: pd.Series(compute_n_jac(row['variantid1'], row['variantid2'])), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc='Processing test')\n",
    "        test_df[['n_jac_words', 'n_jac_ru_words', 'n_jac_en_words', 'n_jac_ru_comb_words', 'n_jac_en_comb_words', 'n_jac_numbers']] = test_df.progress_apply(lambda row: pd.Series(compute_n_jac(row['variantid1'], row['variantid2'])), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = n_jac(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:28:24.739358400Z",
     "start_time": "2024-09-06T16:23:24.324907200Z"
    }
   },
   "id": "8adb004c7a01548d",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 1250672/1250672 [06:19<00:00, 3298.43it/s]\n",
      "Processing test: 100%|██████████| 49620/49620 [00:09<00:00, 5273.12it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('d_jac', False):\n",
    "    def d_jac(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_jac_value(tokens1, tokens2):\n",
    "            \n",
    "            if len(tokens1) == 0  or len(tokens2) == 0 :\n",
    "                if len(tokens1) == 0  and len(tokens2) == 0 :\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "                \n",
    "            intersection = len(tokens1.intersection(tokens2))\n",
    "            union = len(tokens1.union(tokens2))\n",
    "            \n",
    "            return intersection / union if union > 0 else 0\n",
    "        \n",
    "        def compute_d_jac(variantid1, variantid2):\n",
    "            \n",
    "            desc1 = text_df.at[variantid1, 'description']\n",
    "            desc2 = text_df.at[variantid2, 'description']\n",
    "            \n",
    "            if desc1 is None or desc2 is None:\n",
    "                if desc1 is None and desc2 is None:\n",
    "                    return -2, -2, -2, -2, -2, -2\n",
    "                else:\n",
    "                    return -1, -1, -1 , -1, -1, -1\n",
    "            \n",
    "            if len(desc1) == 0  or len(desc2) == 0 :\n",
    "                if len(desc1) == 0  and len(desc2) == 0:\n",
    "                    return -2, -2, -2, -2, -2, -2\n",
    "                else:\n",
    "                    return -1, -1, -1 , -1, -1, -1\n",
    "                \n",
    "            words1 = set(text_df.at[variantid1, 'd_words'].split())\n",
    "            words2 = set(text_df.at[variantid2, 'd_words'].split())\n",
    "            d_jac_words = compute_jac_value(words1, words2)\n",
    "            \n",
    "            ru_words1 = set(text_df.at[variantid1, 'd_ru_words'].split())\n",
    "            ru_words2 = set(text_df.at[variantid2, 'd_ru_words'].split())\n",
    "            d_jac_ru_words = compute_jac_value(ru_words1, ru_words2)\n",
    "            \n",
    "            en_words1 = set(text_df.at[variantid1, 'd_en_words'].split())\n",
    "            en_words2 = set(text_df.at[variantid2, 'd_en_words'].split())\n",
    "            d_jac_en_words = compute_jac_value(en_words1, en_words2)\n",
    "            \n",
    "            ru_comb_words1 = set(text_df.at[variantid1, 'd_ru_comb_words'].split())\n",
    "            ru_comb_words2 = set(text_df.at[variantid2, 'd_ru_comb_words'].split())\n",
    "            d_jac_ru_comb_words = compute_jac_value(ru_comb_words1, ru_comb_words2)\n",
    "            \n",
    "            en_comb_words1 = set(text_df.at[variantid1, 'd_en_comb_words'].split())\n",
    "            en_comb_words2 = set(text_df.at[variantid2, 'd_en_comb_words'].split())\n",
    "            d_jac_en_comb_words = compute_jac_value(en_comb_words1, en_comb_words2)\n",
    "            \n",
    "            numbers1 = set(text_df.at[variantid1, 'd_numbers'].split())\n",
    "            numbers2 = set(text_df.at[variantid2, 'd_numbers'].split())\n",
    "            d_jac_numbers = compute_jac_value(numbers1, numbers2)\n",
    "        \n",
    "            return d_jac_words, d_jac_ru_words, d_jac_en_words, d_jac_ru_comb_words, d_jac_en_comb_words, d_jac_numbers\n",
    "    \n",
    "        tqdm.pandas(desc='Processing train')\n",
    "        train_df[['d_jac_words', 'd_jac_ru_words', 'd_jac_en_words', 'd_jac_ru_comb_words', 'd_jac_en_comb_words', 'd_jac_numbers']] = train_df.progress_apply(lambda row: pd.Series(compute_d_jac(row['variantid1'], row['variantid2'])), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc='Processing test')\n",
    "        test_df[['d_jac_words', 'd_jac_ru_words', 'd_jac_en_words', 'd_jac_ru_comb_words', 'd_jac_en_comb_words', 'd_jac_numbers']] = test_df.progress_apply(lambda row: pd.Series(compute_d_jac(row['variantid1'], row['variantid2'])), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = d_jac(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:34:53.408119900Z",
     "start_time": "2024-09-06T16:28:24.746299100Z"
    }
   },
   "id": "26d4e851499f2d6f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [01:39<00:00, 12557.76it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:03<00:00, 13977.48it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('n_lev_opers', False):\n",
    "    def n_lev_opers(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_n_lev_opers(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'name']\n",
    "            name2 = text_df.at[variantid2, 'name']\n",
    "            \n",
    "            if len(name1.replace(' ', '')) == 0  or len(name2.replace(' ', '')) == 0:\n",
    "                if len(name1.replace(' ', '')) == 0  and len(name2.replace(' ', '')) == 0:\n",
    "                    return -2, -2\n",
    "                else:\n",
    "                    return -1, -1\n",
    "                \n",
    "            operations = Levenshtein.editops(name1, name2)\n",
    "            \n",
    "            insertions = sum(1 for op in operations if op[0] == 'insert')\n",
    "            deletions = sum(1 for op in operations if op[0] == 'delete')\n",
    "            replaces = sum(1 for op in operations if op[0] == 'replace')\n",
    "            \n",
    "            n_lev_var = insertions + deletions\n",
    "            \n",
    "            max_len = max(len(name1), len(name2))\n",
    "            \n",
    "            return n_lev_var / max_len, replaces / max_len\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df[['n_lev_var', 'n_lev_rep']] = train_df.progress_apply(\n",
    "            lambda row: pd.Series(compute_n_lev_opers(row['variantid1'], row['variantid2'])), axis=1)\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df[['n_lev_var', 'n_lev_rep']] = test_df.progress_apply(\n",
    "            lambda row: pd.Series(compute_n_lev_opers(row['variantid1'], row['variantid2'])), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = n_lev_opers(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:36:36.580562Z",
     "start_time": "2024-09-06T16:34:53.404100300Z"
    }
   },
   "id": "ce5821047458ca46",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [04:34<00:00, 4550.70it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:21<00:00, 2277.09it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('d_lev_opers', False):\n",
    "    def d_lev_opers(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_d_lev_opers(variantid1, variantid2):\n",
    "            \n",
    "            desc1 = text_df.at[variantid1, 'description']\n",
    "            desc2 = text_df.at[variantid2, 'description']\n",
    "            \n",
    "            if desc1 is None or desc2 is None:\n",
    "                if desc1 is None and desc2 is None:\n",
    "                    return -2, -2\n",
    "                else:\n",
    "                    return -1, -1\n",
    "            \n",
    "            if len(desc1.replace(' ', '')) == 0  or len(desc2.replace(' ', ''))  == 0:\n",
    "                if len(desc1.replace(' ', '')) == 0  and len(desc2.replace(' ', ''))  == 0:\n",
    "                    return -2, -2\n",
    "                else:\n",
    "                    return -1, -1\n",
    "                \n",
    "            operations = Levenshtein.editops(desc1, desc2)\n",
    "            \n",
    "            insertions = sum(1 for op in operations if op[0] == 'insert')\n",
    "            deletions = sum(1 for op in operations if op[0] == 'delete')\n",
    "            replaces = sum(1 for op in operations if op[0] == 'replace')\n",
    "            \n",
    "            d_lev_var = insertions + deletions\n",
    "            \n",
    "            max_len = max(len(desc1), len(desc2))\n",
    "            \n",
    "            return d_lev_var / max_len, replaces / max_len\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df[['d_lev_var', 'd_lev_rep']] = train_df.progress_apply(\n",
    "            lambda row: pd.Series(compute_d_lev_opers(row['variantid1'], row['variantid2'])), axis=1)\n",
    "    \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df[['d_lev_var', 'd_lev_rep']] = test_df.progress_apply(\n",
    "            lambda row: pd.Series(compute_d_lev_opers(row['variantid1'], row['variantid2'])), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = d_lev_opers(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:41:33.224582700Z",
     "start_time": "2024-09-06T16:36:36.578597Z"
    }
   },
   "id": "20dc2656f1d1238",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [08:22<00:00, 2489.12it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:20<00:00, 2384.55it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('m_cos', False):\n",
    "    def m_cos(train_df, test_df, resnet_df):\n",
    "        \n",
    "        def compute_m_cos(variantid1, variantid2):\n",
    "            \n",
    "            embedding_1 = resnet_df.at[variantid1, 'main_pic_embeddings_resnet_v1'][0]\n",
    "            embedding_2 = resnet_df.at[variantid2, 'main_pic_embeddings_resnet_v1'][0]\n",
    "            \n",
    "            return cosine_similarity([embedding_1], [embedding_2])[0,0]\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['m_cos'] = train_df.progress_apply(lambda row: compute_m_cos(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['m_cos'] = test_df.progress_apply(lambda row: compute_m_cos(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "        \n",
    "    train, test = m_cos(train, test, resnet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:50:16.526603600Z",
     "start_time": "2024-09-06T16:41:33.231583200Z"
    }
   },
   "id": "c3d8c57427b29c0",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [05:39<00:00, 3686.86it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:14<00:00, 3392.58it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('m_evklid', False):\n",
    "    def m_evklid(train_df, test_df, resnet_df):\n",
    "        \n",
    "        def compute_m_evklid(variantid1, variantid2):\n",
    "            \n",
    "            embedding_1 = resnet_df.at[variantid1, 'main_pic_embeddings_resnet_v1'][0]\n",
    "            embedding_2 = resnet_df.at[variantid2, 'main_pic_embeddings_resnet_v1'][0]\n",
    "            \n",
    "            return euclidean_distances([embedding_1], [embedding_2])[0, 0]\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['m_evklid'] = train_df.progress_apply(lambda row: compute_m_evklid(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['m_evklid'] = test_df.progress_apply(lambda row: compute_m_evklid(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "        \n",
    "    train, test = m_evklid(train, test, resnet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:56:10.422660800Z",
     "start_time": "2024-09-06T16:50:16.521626Z"
    }
   },
   "id": "b63b9da9bc699b05",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [08:13<00:00, 2533.29it/s] \n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:08<00:00, 6023.84it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('e_jac', False):\n",
    "    def e_jac(train_df, test_df, resnet_df):\n",
    "        \n",
    "        def calculate_e_jac(v1, v2):\n",
    "            embs1 = resnet_df.at[v1, 'pic_embeddings_resnet_v1']\n",
    "            embs2 = resnet_df.at[v2, 'pic_embeddings_resnet_v1'] \n",
    "            \n",
    "            if embs1 is None or embs2 is None:\n",
    "                if embs1 is None and embs2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            set1 = set(tuple(emb) for emb in embs1)\n",
    "            set2 = set(tuple(emb) for emb in embs2)\n",
    "            \n",
    "            intersection = set1.intersection(set2)\n",
    "            union = set1.union(set2)\n",
    "            \n",
    "            if not union:\n",
    "                return 0\n",
    "\n",
    "            return len(intersection) / len(union)\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['e_jac'] = train_df.progress_apply(lambda row: calculate_e_jac(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['e_jac'] = test_df.progress_apply(lambda row: calculate_e_jac(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "        \n",
    "    train, test = e_jac(train, test, resnet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:04:32.386775600Z",
     "start_time": "2024-09-06T16:56:10.423657400Z"
    }
   },
   "id": "6554351f1a8d4557",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:23<00:00, 53836.14it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:00<00:00, 79253.81it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('e_diff', False):\n",
    "    def e_diff(train_df, test_df, resnet_df):\n",
    "        \n",
    "        def count_e_diff(variantid1, variantid2):\n",
    "            emb1 = resnet_df.at[variantid1, 'pic_embeddings_resnet_v1']\n",
    "            emb2 = resnet_df.at[variantid2, 'pic_embeddings_resnet_v1']\n",
    "            \n",
    "            if emb1 is None or emb2 is None:\n",
    "                if emb1 is None and emb2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            return abs(len(emb1) - len(emb2)) / max(len(emb1), len(emb2))\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['e_diff'] = train_df.progress_apply(lambda row: count_e_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['e_diff'] = test_df.progress_apply(lambda row: count_e_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "        \n",
    "    train, test = e_diff(train, test, resnet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:04:56.275858500Z",
     "start_time": "2024-09-06T17:04:32.394741400Z"
    }
   },
   "id": "57c0969605ef5195",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [06:42<00:00, 3109.11it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:16<00:00, 3076.62it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('m_ent_diff', False):\n",
    "    def m_ent_diff(train_df, test_df, resnet_df):\n",
    "        \n",
    "        def compute_entropy_diff(embedding):\n",
    "            \n",
    "            norm_embedding = np.abs(embedding) / np.sum(np.abs(embedding))\n",
    "            \n",
    "            return entropy(norm_embedding)\n",
    "    \n",
    "        def compute_m_ent_diff(variantid1, variantid2):\n",
    "            embedding1 = resnet_df.at[variantid1, 'main_pic_embeddings_resnet_v1'][0]\n",
    "            embedding2 = resnet_df.at[variantid2, 'main_pic_embeddings_resnet_v1'][0]\n",
    "    \n",
    "            entropy1 = compute_entropy_diff(embedding1)\n",
    "            entropy2 = compute_entropy_diff(embedding2)\n",
    "            \n",
    "            return abs(entropy1 - entropy2)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['m_ent_diff'] = train_df.progress_apply(lambda row: compute_m_ent_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['m_ent_diff'] = test_df.progress_apply(lambda row: compute_m_ent_diff(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "    \n",
    "    train, test = m_ent_diff(train, test, resnet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:11:54.718643700Z",
     "start_time": "2024-09-06T17:04:56.282769600Z"
    }
   },
   "id": "8c9fe415582a0540",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [03:19<00:00, 6269.16it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:07<00:00, 6401.43it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('e_avg_cos', False):\n",
    "    def e_avg_cos(train_df, test_df, resnet_df):\n",
    "        \n",
    "        def average_embedding(embeddings):\n",
    "            return np.mean(embeddings, axis=0)\n",
    "\n",
    "        def calculate_e_avg_cos(v1, v2):\n",
    "            emb1 = resnet_df.at[v1, 'pic_embeddings_resnet_v1']\n",
    "            emb2 = resnet_df.at[v2, 'pic_embeddings_resnet_v1'] \n",
    "            \n",
    "            if emb1 is None or emb2 is None:\n",
    "                if emb1 is None and emb2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "            return cosine_similarity([average_embedding(emb1)], [average_embedding(emb2)])[0, 0]\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['e_avg_cos'] = train_df.progress_apply(lambda row: calculate_e_avg_cos(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['e_avg_cos'] = test_df.progress_apply(lambda row: calculate_e_avg_cos(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "        \n",
    "    train, test = e_avg_cos(train, test, resnet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:15:21.987943600Z",
     "start_time": "2024-09-06T17:11:54.711589700Z"
    }
   },
   "id": "62fc70fa700fc1ac",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250672/1250672 [01:18<00:00, 15996.65it/s]\n"
     ]
    }
   ],
   "source": [
    "wrong_indexes = []\n",
    "for index, row in tqdm(train.iterrows(), total=len(train)):\n",
    "    if row['target'] == 1:\n",
    "        continue\n",
    "    \n",
    "    v1 = row['variantid1']\n",
    "    v2 = row['variantid2']\n",
    "    \n",
    "    name1 = text.loc[v1, 'name']\n",
    "    name2 = text.loc[v2, 'name']\n",
    "    \n",
    "    desc1 = text.loc[v1, 'description']\n",
    "    desc2 = text.loc[v2, 'description']\n",
    "    \n",
    "    if desc1 is None:\n",
    "        desc1 = ''\n",
    "    if desc2 is None:\n",
    "        desc2 = ''\n",
    "        \n",
    "    e = row['e_jac']\n",
    "    m_cos = row['m_cos']\n",
    "    jac_vals = row['jac_vals']\n",
    "    \n",
    "    if name1.replace(' ', '') == name2.replace(' ', '') or name1 == '' or name2 == '':\n",
    "        if desc1.replace(' ', '') == desc2.replace(' ', '') or desc1 == '' or desc2 == '':\n",
    "            if jac_vals == 1:\n",
    "                if m_cos == 1:\n",
    "                    if e == 1 or e == -1 or e == -2:\n",
    "                        wrong_indexes.append(index)\n",
    "                        \n",
    "train.loc[wrong_indexes, 'target'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:16:40.218169400Z",
     "start_time": "2024-09-06T17:15:21.986943800Z"
    }
   },
   "id": "74ef34f51670bed7",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [00:38<00:00, 32281.24it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 31867.04it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('n_jac', False):\n",
    "    def n_jac(train_df, test_df, text_df):\n",
    "        # Функция для создания биграмм из текста\n",
    "        def create_bigrams(text):\n",
    "            bigrams = []\n",
    "            for i in range(len(text) - 1):\n",
    "                bigrams.append((text[i], text[i + 1]))\n",
    "            return bigrams\n",
    "        \n",
    "        # Функция для фильтрации биграмм\n",
    "        def filter_bigrams(bigrams):\n",
    "            return [(w1, w2) for (w1, w2) in bigrams if re.match(r'\\d+', w1)]\n",
    "        \n",
    "        def compute_n_jac(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'name']\n",
    "            name2 = text_df.at[variantid2, 'name']\n",
    "\n",
    "            \n",
    "            words1 = re.sub(r'[^\\w\\s]', ' ', name1)\n",
    "            words1 = words1.replace('_', ' ')\n",
    "            words1 = re.sub(r'\\s+', ' ', words1)\n",
    "            words1 = words1.strip().split()\n",
    "            \n",
    "            words2 = re.sub(r'[^\\w\\s]', ' ', name2)\n",
    "            words2 = words2.replace('_', ' ')\n",
    "            words2 = re.sub(r'\\s+', ' ', words2)\n",
    "            words2 = words2.strip().split()\n",
    "                \n",
    "            # Создаем биграммы из обоих списков слов\n",
    "            bigrams1 = create_bigrams(words1)\n",
    "            bigrams2 = create_bigrams(words2)\n",
    "            \n",
    "            # Фильтруем биграммы\n",
    "            filtered_bigrams1 = filter_bigrams(bigrams1)\n",
    "            filtered_bigrams2 = filter_bigrams(bigrams2)\n",
    "            \n",
    "            length = 0\n",
    "            counter = 0\n",
    "            \n",
    "            for w1, w2 in filtered_bigrams1:\n",
    "                for x1, x2 in filtered_bigrams2:\n",
    "                    if w2 == x2:\n",
    "                        length += 1\n",
    "                        if w1 == x1:\n",
    "                            counter += 1\n",
    "            \n",
    "            if length != 0:\n",
    "                return counter / length\n",
    "            else:\n",
    "                return -3\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['n_trick'] = train_df.progress_apply(lambda row: compute_n_jac(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['n_trick'] = test_df.progress_apply(lambda row: compute_n_jac(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = n_jac(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:17:20.561168200Z",
     "start_time": "2024-09-06T17:16:40.226201700Z"
    }
   },
   "id": "c85efb5dcc2dad60",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250672/1250672 [07:32<00:00, 2764.13it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:20<00:00, 2462.38it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('d_jac', False):\n",
    "    def n_jac(train_df, test_df, text_df):\n",
    "        # Функция для создания биграмм из текста\n",
    "        def create_bigrams(text):\n",
    "            bigrams = []\n",
    "            for i in range(len(text) - 1):\n",
    "                bigrams.append((text[i], text[i + 1]))\n",
    "            return bigrams\n",
    "        \n",
    "        # Функция для фильтрации биграмм\n",
    "        def filter_bigrams(bigrams):\n",
    "            return [(w1, w2) for (w1, w2) in bigrams if re.match(r'\\d+', w1)]\n",
    "        \n",
    "        def compute_n_jac(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'description']\n",
    "            name2 = text_df.at[variantid2, 'description']\n",
    "                \n",
    "            if name1 is None or name2 is None:\n",
    "                if name1 is None and name2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "\n",
    "            \n",
    "            \n",
    "            words1 = re.sub(r'[^\\w\\s]', ' ', name1)\n",
    "            words1 = words1.replace('_', ' ')\n",
    "            words1 = re.sub(r'\\s+', ' ', words1)\n",
    "            words1 = words1.strip().split()\n",
    "            \n",
    "            words2 = re.sub(r'[^\\w\\s]', ' ', name2)\n",
    "            words2 = words2.replace('_', ' ')\n",
    "            words2 = re.sub(r'\\s+', ' ', words2)\n",
    "            words2 = words2.strip().split()\n",
    "                \n",
    "            # Создаем биграммы из обоих списков слов\n",
    "            bigrams1 = create_bigrams(words1)\n",
    "            bigrams2 = create_bigrams(words2)\n",
    "            \n",
    "            # Фильтруем биграммы\n",
    "            filtered_bigrams1 = filter_bigrams(bigrams1)\n",
    "            filtered_bigrams2 = filter_bigrams(bigrams2)\n",
    "            \n",
    "            length = 0\n",
    "            counter = 0\n",
    "            \n",
    "            for w1, w2 in filtered_bigrams1:\n",
    "                for x1, x2 in filtered_bigrams2:\n",
    "                    if w2 == x2:\n",
    "                        length += 1\n",
    "                        if w1 == x1:\n",
    "                            counter += 1\n",
    "            \n",
    "            if length != 0:\n",
    "                return counter / length\n",
    "            else:\n",
    "                return -3\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['d_trick'] = train_df.progress_apply(lambda row: compute_n_jac(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['d_trick'] = test_df.progress_apply(lambda row: compute_n_jac(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = n_jac(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:25:13.218985400Z",
     "start_time": "2024-09-06T17:17:20.568185800Z"
    }
   },
   "id": "fc5e6aec0393bd77",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250672/1250672 [00:48<00:00, 25581.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "indexes = []\n",
    "for index, row in tqdm(train.iterrows(), total=len(train)):\n",
    "\n",
    "    cat1 = json.loads(attributes.at[row['variantid1'], 'categories'])\n",
    "    cat2 = json.loads(attributes.at[row['variantid2'], 'categories'])\n",
    "\n",
    "    if cat1['2'] != cat2['2']:\n",
    "        indexes.append(index)\n",
    "train.drop(index=indexes, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:26:02.360884Z",
     "start_time": "2024-09-06T17:25:13.230990300Z"
    }
   },
   "id": "c76806b73cf67d6f",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250160/1250160 [00:27<00:00, 46042.11it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:01<00:00, 40086.10it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('n_years', False):\n",
    "    def n_years(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_n_years(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'name']\n",
    "            name2 = text_df.at[variantid2, 'name']\n",
    "                \n",
    "            if len(name1.replace(' ', '')) == 0  or len(name2.replace(' ', '')) == 0:\n",
    "                if len(name1.replace(' ', '')) == 0  and len(name2.replace(' ', '')) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "                \n",
    "            words1 = re.sub(r'[^\\w\\s]', ' ', name1) # Unicode токены\n",
    "            words1 = words1.replace('_', ' ') # Удаление _ символов\n",
    "            words1 = ' '.join(re.findall(r'\\b\\d{4}\\b', words1))\n",
    "            words1 = re.sub(r'\\s+', ' ', words1) # Удаление лишних пробелов\n",
    "            words1 = set(words1.strip().split()) # Удаление пробелов в начале и конце\n",
    "            \n",
    "            words2 = re.sub(r'[^\\w\\s]', ' ', name2) # Unicode токены\n",
    "            words2 = words2.replace('_', ' ') # Удаление _ символов\n",
    "            words2 = ' '.join(re.findall(r'\\b\\d{4}\\b', words2))\n",
    "            words2 = re.sub(r'\\s+', ' ', words2) # Удаление лишних пробелов\n",
    "            words2 = set(words2.strip().split()) # Удаление пробелов в начале и конце\n",
    "            \n",
    "            if len(words1) == 0 or len(words2) == 0:\n",
    "                if len(words1) == 0 and len(words2) == 0:\n",
    "                    return -4\n",
    "                else:\n",
    "                    return -3\n",
    "            \n",
    "            intersection = len(words1.intersection(words2))\n",
    "            union = len(words1.intersection(words2))\n",
    "            \n",
    "            \n",
    "            return intersection / union if union != 0 else 0\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['n_years'] = train_df.progress_apply(lambda row: compute_n_years(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['n_years'] = test_df.progress_apply(lambda row: compute_n_years(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = n_years(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:26:30.791194900Z",
     "start_time": "2024-09-06T17:26:02.373847100Z"
    }
   },
   "id": "abd9b033597c588f",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train_df: 100%|██████████| 1250160/1250160 [01:39<00:00, 12550.75it/s]\n",
      "Processing test_df: 100%|██████████| 49620/49620 [00:03<00:00, 16376.42it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.get('d_years', False):\n",
    "    def d_years(train_df, test_df, text_df):\n",
    "        \n",
    "        def compute_d_years(variantid1, variantid2):\n",
    "            \n",
    "            name1 = text_df.at[variantid1, 'description']\n",
    "            name2 = text_df.at[variantid2, 'description']\n",
    "                \n",
    "            if name1 is None or name2 is None:\n",
    "                if name1 is None and name2 is None:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "                \n",
    "            if len(name1.replace(' ', '')) == 0  or len(name2.replace(' ', '')) == 0:\n",
    "                if len(name1.replace(' ', '')) == 0  and len(name2.replace(' ', '')) == 0:\n",
    "                    return -2\n",
    "                else:\n",
    "                    return -1\n",
    "            \n",
    "                \n",
    "            words1 = re.sub(r'[^\\w\\s]', ' ', name1) # Unicode токены\n",
    "            words1 = words1.replace('_', ' ') # Удаление _ символов\n",
    "            words1 = ' '.join(re.findall(r'\\b\\d{4}\\b', words1))\n",
    "            words1 = re.sub(r'\\s+', ' ', words1) # Удаление лишних пробелов\n",
    "            words1 = set(words1.strip().split()) # Удаление пробелов в начале и конце\n",
    "            \n",
    "            words2 = re.sub(r'[^\\w\\s]', ' ', name2) # Unicode токены\n",
    "            words2 = words2.replace('_', ' ') # Удаление _ символов\n",
    "            words2 = ' '.join(re.findall(r'\\b\\d{4}\\b', words2))\n",
    "            words2 = re.sub(r'\\s+', ' ', words2) # Удаление лишних пробелов\n",
    "            words2 = set(words2.strip().split()) # Удаление пробелов в начале и конце\n",
    "            \n",
    "            if len(words1) == 0 or len(words2) == 0:\n",
    "                if len(words1) == 0 and len(words2) == 0:\n",
    "                    return -4\n",
    "                else:\n",
    "                    return -3\n",
    "            \n",
    "            intersection = len(words1.intersection(words2))\n",
    "            union = len(words1.intersection(words2))\n",
    "            \n",
    "            \n",
    "            return intersection / union if union != 0 else 0\n",
    "\n",
    "        tqdm.pandas(desc=\"Processing train_df\")\n",
    "        train_df['d_years'] = train_df.progress_apply(lambda row: compute_d_years(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        tqdm.pandas(desc=\"Processing test_df\")\n",
    "        test_df['d_years'] = test_df.progress_apply(lambda row: compute_d_years(row['variantid1'], row['variantid2']), axis=1)\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "    train, test = d_years(train, test, text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:28:13.467646700Z",
     "start_time": "2024-09-06T17:26:30.802248200Z"
    }
   },
   "id": "83365731bcffc7aa",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train.to_csv('1_my_train.csv', index=False)\n",
    "test.to_csv('1_my_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T17:28:42.693951900Z",
     "start_time": "2024-09-06T17:28:13.459645800Z"
    }
   },
   "id": "80a4e66dfe58ffdf",
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
